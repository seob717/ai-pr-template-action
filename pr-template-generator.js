#!/usr/bin/env node

import { execSync } from "child_process";
import fs from "fs";
import path from "path";

// AI Provider imports
let Anthropic, OpenAI, GoogleGenerativeAI, Groq;

// Dynamic imports based on provider
async function importAISDKs() {
  try {
    const anthropicModule = await import("@anthropic-ai/sdk");
    Anthropic = anthropicModule.Anthropic;
  } catch (e) {}

  try {
    const openaiModule = await import("openai");
    OpenAI = openaiModule.OpenAI;
  } catch (e) {}

  try {
    const googleModule = await import("@google/generative-ai");
    GoogleGenerativeAI = googleModule.GoogleGenerativeAI;
  } catch (e) {}

  try {
    const groqModule = await import("groq-sdk");
    Groq = groqModule.Groq;
  } catch (e) {}
}

class PRTemplateGenerator {
  constructor() {
    this.templateDir = process.env.TEMPLATE_PATH
      ? path.join(process.cwd(), process.env.TEMPLATE_PATH)
      : path.join(process.cwd(), ".github", "pull_request_templates");

    this.aiProvider = process.env.AI_PROVIDER || "claude";
    this.apiKey = this.getAPIKey();
    this.model = this.getModel();

    // API í‚¤ ê²€ì¦
    if (!this.apiKey) {
      console.log(
        "âš ï¸ No API key found. Will use basic template without AI generation."
      );
    }
  }

  // API í‚¤ ê°€ì ¸ì˜¤ê¸° (ìš°ì„ ìˆœìœ„: api-key > ê°œë³„ í‚¤)
  getAPIKey() {
    if (process.env.API_KEY) return process.env.API_KEY;

    switch (this.aiProvider) {
      case "claude":
        return process.env.ANTHROPIC_API_KEY;
      case "openai":
        return process.env.OPENAI_API_KEY;
      case "google":
        return process.env.GOOGLE_API_KEY;
      case "vertex-ai":
        return process.env.VERTEX_AI_API_KEY;
      case "groq":
        return process.env.GROQ_API_KEY;
      default:
        return process.env.ANTHROPIC_API_KEY;
    }
  }

  // ëª¨ë¸ ì„ íƒ
  getModel() {
    if (process.env.MODEL) return process.env.MODEL;

    const defaultModels = {
      claude: "claude-3-5-sonnet-20241022", // ìµœì‹  ê³ ì„±ëŠ¥ ëª¨ë¸
      openai: "gpt-4o", // ê³ ì„±ëŠ¥ ëª¨ë¸ (ë¬´ë£Œ í‹°ì–´ ì œí•œì )
      google: "gemini-1.5-flash", // ë¬´ë£Œ í‹°ì–´ ìˆìŒ
      "vertex-ai": "gemini-1.5-pro", // ê¸°ì—…ìš© ê³ ì„±ëŠ¥
      groq: "llama-3.1-70b-versatile", // ë” í° ëª¨ë¸
      huggingface: "microsoft/DialoGPT-medium", // ë¬´ë£Œ
    };

    return defaultModels[this.aiProvider] || defaultModels.claude;
  }

  // Git diff ë¶„ì„
  getGitDiff() {
    try {
      const diff = execSync("git diff HEAD~1..HEAD", { encoding: "utf8" });
      const changedFiles = execSync("git diff --name-only HEAD~1..HEAD", {
        encoding: "utf8",
      })
        .split("\n")
        .filter((file) => file.trim());

      return { diff, changedFiles };
    } catch (error) {
      console.error("Git diff ë¶„ì„ ì‹¤íŒ¨:", error.message);
      return { diff: "", changedFiles: [] };
    }
  }

  // ë¸Œëœì¹˜ëª…ì´ë‚˜ ì»¤ë°‹ ë©”ì‹œì§€ë¡œ í…œí”Œë¦¿ ì„ íƒ
  selectTemplate() {
    try {
      const branchName = execSync("git branch --show-current", {
        encoding: "utf8",
      }).trim();
      const lastCommit = execSync("git log -1 --pretty=%B", {
        encoding: "utf8",
      }).trim();

      // ë¸Œëœì¹˜ëª… ê¸°ë°˜ ì„ íƒ
      if (branchName.includes("hotfix")) return "hotfix";
      if (branchName.includes("release")) return "release";
      if (branchName.includes("feature") || branchName.includes("feat"))
        return "feature";
      if (branchName.includes("bugfix") || branchName.includes("bug"))
        return "bugfix";

      // ì»¤ë°‹ ë©”ì‹œì§€ ê¸°ë°˜ ì„ íƒ
      if (lastCommit.toLowerCase().startsWith("hotfix")) return "hotfix";
      if (lastCommit.toLowerCase().startsWith("feat")) return "feature";
      if (lastCommit.toLowerCase().startsWith("fix")) return "bugfix";
      if (lastCommit.toLowerCase().startsWith("release")) return "release";

      return "feature"; // ê¸°ë³¸ê°’
    } catch (error) {
      console.error("í…œí”Œë¦¿ ì„ íƒ ì‹¤íŒ¨:", error.message);
      return "feature";
    }
  }

  // í…œí”Œë¦¿ íŒŒì¼ ì½ê¸°
  readTemplate(templateName) {
    const templatePath = path.join(this.templateDir, `${templateName}.md`);
    if (fs.existsSync(templatePath)) {
      return fs.readFileSync(templatePath, "utf8");
    }

    // ê¸°ë³¸ í…œí”Œë¦¿ ìƒì„±
    console.log(
      `í…œí”Œë¦¿ íŒŒì¼ì´ ì—†ì–´ì„œ ê¸°ë³¸ í…œí”Œë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤: ${templatePath}`
    );
    return this.createDefaultTemplate(templateName);
  }

  // ê¸°ë³¸ í…œí”Œë¦¿ ìƒì„±
  createDefaultTemplate(templateName) {
    const templates = {
      feature: `## ğŸ¯ Feature Description

<!-- AIê°€ ìë™ìœ¼ë¡œ ì±„ì›Œì¤ë‹ˆë‹¤ -->

## ğŸ”„ Changes Made

<!-- AIê°€ ìë™ìœ¼ë¡œ ì±„ì›Œì¤ë‹ˆë‹¤ -->

## ğŸ§ª Testing

- [ ] Manual testing completed

## ğŸ“ Notes for Reviewers

<!-- AIê°€ ìë™ìœ¼ë¡œ ì±„ì›Œì¤ë‹ˆë‹¤ -->`,
      default: `## Description

<!-- AIê°€ ìë™ìœ¼ë¡œ ì±„ì›Œì¤ë‹ˆë‹¤ -->

## Changes

<!-- AIê°€ ìë™ìœ¼ë¡œ ì±„ì›Œì¤ë‹ˆë‹¤ -->

## Testing

<!-- AIê°€ ìë™ìœ¼ë¡œ ì±„ì›Œì¤ë‹ˆë‹¤ -->`,
    };

    return templates[templateName] || templates.default;
  }

  // AI APIë¡œ ë‚´ìš© ìƒì„± (ë‹¤ì¤‘ ì œê³µì ì§€ì›)
  async generateContent(diff, changedFiles, template) {
    const systemPrompt = `You are an AI assistant that automatically generates Pull Request descriptions from git diffs.
Your task is to fill out the provided PR template in Korean based on the code changes.

Instructions:
1.  **Analyze the Changes**: Carefully review the git diff and the list of changed files.
2.  **Fill the Template**: Populate each section of the PR template with concise and clear descriptions.
3.  **Replace Placeholders**: Replace every \`<!-- AIê°€ ìë™ìœ¼ë¡œ ì±„ì›Œì¤ë‹ˆë‹¤ -->\` placeholder with relevant content.
4.  **Handle Non-applicable Sections**: If a section is not relevant to the changes, write "í•´ë‹¹ ì—†ìŒ".
5.  **Estimate Review Time**: If the template includes "ì˜ˆìƒ ë¦¬ë·° ì†Œìš” ì‹œê°„" (Estimated review time), provide a realistic estimate (e.g., 5ë¶„, 15ë¶„, 30ë¶„) based on the complexity of the changes.
6.  **Suggest Deadline**: If there's a "í¬ë§ ë¦¬ë·° ë§ˆê° ê¸°í•œ" (Desired review deadline), suggest a reasonable deadline (e.g., ë‚´ì¼ ì˜¤ì „, ê¸ˆìš”ì¼ê¹Œì§€).
7.  **Maintain Structure**: Preserve the original Markdown formatting of the template.`;

    const userPrompt = `Please fill out the following PR template based on the provided git diff.

**Changed Files:**
\`\`\`
${changedFiles.join("\n")}
\`\`\`

**Git Diff:**
\`\`\`diff
${diff}
\`\`\`

**PR Template:**
---
${template}
---
`;

    try {
      console.log(`ğŸ¤– Using ${this.aiProvider} with model ${this.model}`);

      switch (this.aiProvider) {
        case "claude":
          return await this.generateWithClaude(systemPrompt, userPrompt);
        case "openai":
          return await this.generateWithOpenAI(systemPrompt, userPrompt);
        case "google":
          return await this.generateWithGoogle(systemPrompt, userPrompt);
        case "vertex-ai":
          return await this.generateWithVertexAI(systemPrompt, userPrompt);
        case "groq":
          return await this.generateWithGroq(systemPrompt, userPrompt);
        case "huggingface":
          return await this.generateWithHuggingFace(systemPrompt, userPrompt);
        default:
          throw new Error(`Unsupported AI provider: ${this.aiProvider}`);
      }
    } catch (error) {
      console.error(`${this.aiProvider} API í˜¸ì¶œ ì‹¤íŒ¨:`, error.message);
      return null;
    }
  }

  async generateWithClaude(systemPrompt, userPrompt) {
    const anthropic = new Anthropic({ apiKey: this.apiKey });
    const message = await anthropic.messages.create({
      model: this.model,
      max_tokens: 1000,
      system: systemPrompt,
      messages: [{ role: "user", content: userPrompt }],
    });
    return message.content[0].text;
  }

  async generateWithOpenAI(systemPrompt, userPrompt) {
    const openai = new OpenAI({ apiKey: this.apiKey });
    const completion = await openai.chat.completions.create({
      model: this.model,
      max_tokens: 1000,
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: userPrompt },
      ],
    });
    return completion.choices[0].message.content;
  }

  async generateWithGoogle(systemPrompt, userPrompt) {
    const genAI = new GoogleGenerativeAI(this.apiKey);
    const model = genAI.getGenerativeModel({ model: this.model });
    const result = await model.generateContent([
      { text: systemPrompt },
      { text: userPrompt },
    ]);
    return result.response.text();
  }

  async generateWithVertexAI(systemPrompt, userPrompt) {
    const projectId = process.env.PROJECT_ID;
    const location = process.env.LOCATION || "us-central1";

    if (!projectId) {
      throw new Error(
        "PROJECT_ID environment variable is required for Vertex AI"
      );
    }

    const endpoint = `https://${location}-aiplatform.googleapis.com/v1/projects/${projectId}/locations/${location}/publishers/google/models/${this.model}:generateContent`;

    const response = await fetch(endpoint, {
      method: "POST",
      headers: {
        Authorization: `Bearer ${this.apiKey}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        contents: [
          {
            role: "user",
            parts: [
              {
                text: `${systemPrompt}\n\n${userPrompt}`,
              },
            ],
          },
        ],
        generationConfig: {
          maxOutputTokens: 1000,
          temperature: 0.7,
        },
      }),
    });

    if (!response.ok) {
      throw new Error(
        `Vertex AI API error: ${response.status} ${response.statusText}`
      );
    }

    const result = await response.json();
    return result.candidates[0].content.parts[0].text;
  }

  async generateWithGroq(systemPrompt, userPrompt) {
    const groq = new Groq({ apiKey: this.apiKey });
    const completion = await groq.chat.completions.create({
      model: this.model,
      max_tokens: 1000,
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: userPrompt },
      ],
    });
    return completion.choices[0].message.content;
  }

  async generateWithHuggingFace(systemPrompt, userPrompt) {
    const response = await fetch(
      `https://api-inference.huggingface.co/models/${this.model}`,
      {
        method: "POST",
        headers: {
          Authorization: `Bearer ${this.apiKey}`,
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          inputs: `${systemPrompt}\n\nUser: ${userPrompt}`,
          parameters: { max_length: 1000 },
        }),
      }
    );

    const result = await response.json();
    return result[0]?.generated_text || result.generated_text;
  }

  // í…œí”Œë¦¿ì— ìƒì„±ëœ ë‚´ìš© ì ìš©
  fillTemplate(template, generatedContent) {
    if (!generatedContent) {
      return template; // AI ìƒì„± ì‹¤íŒ¨ì‹œ ì›ë³¸ í…œí”Œë¦¿ ë°˜í™˜
    }

    // AIê°€ ìƒì„±í•œ ë‚´ìš©ì—ì„œ í…œí”Œë¦¿ ì‹œì‘/ë êµ¬ë¶„ì„ ì„ ì œê±°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    const cleanedContent = generatedContent.replace(/---/g, "").trim();

    // AIê°€ ì´ë¯¸ ì „ì²´ í…œí”Œë¦¿ì„ ì±„ì›Œì„œ ë°˜í™˜í•˜ë¯€ë¡œ, ê·¸ ë‚´ìš©ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    // ë§Œì•½ AIê°€ í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ë‚¨ê²¨ë‘ì—ˆë‹¤ë©´, ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    return cleanedContent.replace(
      /<!-- AIê°€ ìë™ìœ¼ë¡œ ì±„ì›Œì¤ë‹ˆë‹¤ -->/g,
      "í•´ë‹¹ ì—†ìŒ"
    );
  }

  // ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
  async generate() {
    try {
      console.log("ğŸ¤– AI PR Template Generator ì‹œì‘...");
      console.log(`ğŸ“¡ AI Provider: ${this.aiProvider}`);
      console.log(`ğŸ¯ Model: ${this.model}`);

      // 1. Git diff ë¶„ì„
      const { diff, changedFiles } = this.getGitDiff();
      if (!diff && changedFiles.length === 0) {
        console.log("ë³€ê²½ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.");
        this.setOutput("content-generated", "false");
        return;
      }

      // 2. í…œí”Œë¦¿ ì„ íƒ
      const templateName = this.selectTemplate();
      console.log(`ğŸ“‹ ì„ íƒëœ í…œí”Œë¦¿: ${templateName}`);
      this.setOutput("template-used", templateName);

      // 3. í…œí”Œë¦¿ ì½ê¸°
      const template = this.readTemplate(templateName);

      // 4. AIë¡œ ë‚´ìš© ìƒì„±
      let generatedContent = null;
      let filledTemplate = template;

      if (this.apiKey) {
        console.log("ğŸ§  AIë¡œ ë‚´ìš© ìƒì„± ì¤‘...");
        generatedContent = await this.generateContent(
          diff,
          changedFiles,
          template
        );

        if (generatedContent) {
          // 5. í…œí”Œë¦¿ ì±„ìš°ê¸°
          filledTemplate = this.fillTemplate(template, generatedContent);
        } else {
          console.log("âš ï¸ AI ìƒì„± ì‹¤íŒ¨, ê¸°ë³¸ í…œí”Œë¦¿ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.");
        }
      } else {
        console.log("â„¹ï¸ API í‚¤ê°€ ì—†ì–´ì„œ ê¸°ë³¸ í…œí”Œë¦¿ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.");
      }

      // 6. íŒŒì¼ë¡œ ì €ì¥ (GitHub Actionì—ì„œ ì‚¬ìš©)
      fs.writeFileSync("pr-template-output.md", filledTemplate);
      this.setOutput("content-generated", "true");

      console.log("âœ… PR í…œí”Œë¦¿ ìƒì„± ì™„ë£Œ");

      return filledTemplate;
    } catch (error) {
      console.error("âŒ PR í…œí”Œë¦¿ ìƒì„± ì‹¤íŒ¨:", error.message);
      this.setOutput("content-generated", "false");
      process.exit(1);
    }
  }

  // GitHub Actions output ì„¤ì • (ìƒˆë¡œìš´ ë°©ì‹)
  setOutput(name, value) {
    if (process.env.GITHUB_OUTPUT) {
      fs.appendFileSync(process.env.GITHUB_OUTPUT, `${name}=${value}\n`);
    } else {
      // ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© fallback
      console.log(`::set-output name=${name}::${value}`);
    }
  }
}

// ì‹¤í–‰
if (import.meta.url === `file://${process.argv[1]}`) {
  await importAISDKs();
  const generator = new PRTemplateGenerator();
  await generator.generate();
}

export default PRTemplateGenerator;
